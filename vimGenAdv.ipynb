{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f8daf2-d6b2-4f8c-9a0d-e8c35bf57ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/jupyter/AdversarialRobustness')\n",
    "sys.path.insert(0, '/home/jupyter/AdversarialRobustness/vim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81724da-83ea-45bd-86ba-71bc94ea5576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "#!pip install -r AdversarialRobustness/vim_requirements.txt\n",
    "#!pip install causal-conv1d==1.1.0\n",
    "#!pip install mamba-ssm==1.1.1\n",
    "#!pip install timm\n",
    "#!pip install -r AdversarialRobustness/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f591ba3-35dd-4b95-a862-a9fc53accc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sbin to path for Trigon - fix of common Debian error\n",
    "import os\n",
    "original_path = os.environ.get('PATH')\n",
    "os.environ['PATH'] = original_path + ':/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7386e198-9c1f-490a-b688-5ab52eb55892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import mamba_ssm\n",
    "#mamba_ssm.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439acb50-d23c-4a61-ba8f-1cf90f2100ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace pip mamba_ssm with author modification\n",
    "#!rm -rf /opt/conda/envs/pytorch/lib/python3.10/site-packages/mamba_ssm\n",
    "#!cp -r ./mamba_ssm /opt/conda/envs/pytorch/lib/python3.10/site-packages/mamba_ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "030af9d9-7f51-48ad-b83b-ec1f10291090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import loadVim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047c4f9c-c33b-4630-9e09-25371787a253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load util functions to generate adversarial dataset\n",
    "from captum.robust import FGSM, MinParamPerturbation\n",
    "from genAdvDataset import fgsmAttack, calcImageDistanceMetrics, saveImageTensor, genImageNetteConvDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05562c2c-1c65-4631-8d18-e1f8ddd0b76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use ViT for config, as Vim doesn't contain metadata\n",
    "confproxymod = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "netteToImageNetConv = genImageNetteConvDict(confproxymod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ecc43-5646-414f-81b2-31c932f9c0f4",
   "metadata": {},
   "source": [
    "# Generate Baseline Adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5619e8a-7b2d-492c-bcb6-41d356e5170e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_0 is a tench, Tinca tinca but classifies as French horn, horn with epsilon 0.191\n",
      "adv_1 is a tench, Tinca tinca but classifies as gasmask, respirator, gas helmet with epsilon 0.20400000000000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m label:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# We only care for adversarial examples in the case when the model could correctly predict otherwise\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     attack_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_label\u001b[39m\u001b[38;5;124m'\u001b[39m:label}\n\u001b[0;32m---> 61\u001b[0m     alt_im, min_eps \u001b[38;5;241m=\u001b[39m \u001b[43mmin_pert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattack_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattack_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     altpred \u001b[38;5;241m=\u001b[39m pred(alt_im, model)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label[label\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but classifies as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label[altpred\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with epsilon \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_eps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/captum/robust/_core/metrics/min_param_perturbation.py:452\u001b[0m, in \u001b[0;36mMinParamPerturbation.evaluate\u001b[0;34m(self, inputs, additional_forward_args, target, perturbations_per_eval, attack_kwargs, correct_fn_kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChosen MinParamPerturbationMode is not supported!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msearch_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreproc_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattack_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpanded_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorrect_fn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperturbations_per_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/captum/robust/_core/metrics/min_param_perturbation.py:313\u001b[0m, in \u001b[0;36mMinParamPerturbation._binary_search\u001b[0;34m(self, inputs, preproc_input, attack_kwargs, additional_forward_args, expanded_additional_args, correct_fn_kwargs, target, perturbations_per_eval)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_list) \u001b[38;5;241m!=\u001b[39m perturbations_per_eval:\n\u001b[1;32m    309\u001b[0m     additional_args \u001b[38;5;241m=\u001b[39m _expand_additional_forward_args(\n\u001b[1;32m    310\u001b[0m         additional_forward_args, \u001b[38;5;28mlen\u001b[39m(input_list)\n\u001b[1;32m    311\u001b[0m     )\n\u001b[0;32m--> 313\u001b[0m successful_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorrect_fn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m successful_ind \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     attack_success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/captum/robust/_core/metrics/min_param_perturbation.py:167\u001b[0m, in \u001b[0;36mMinParamPerturbation._evaluate_batch\u001b[0;34m(self, input_list, additional_forward_args, correct_fn_kwargs, target)\u001b[0m\n\u001b[1;32m    164\u001b[0m     all_kwargs\u001b[38;5;241m.\u001b[39mupdate(correct_fn_kwargs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     out_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrect_fn(model_out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_metric \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m dataLoader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Adversarial attack\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Min Param Perturbation works only with batch size 1 for our purposes\u001b[39;00m\n\u001b[1;32m     30\u001b[0m min_pert \u001b[38;5;241m=\u001b[39m MinParamPerturbation(\n\u001b[0;32m---> 31\u001b[0m                                 forward_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits,\n\u001b[1;32m     32\u001b[0m                                 attack \u001b[38;5;241m=\u001b[39m fgsmAttack,\n\u001b[1;32m     33\u001b[0m                                 arg_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m                                 mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m                                 arg_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     36\u001b[0m                                 arg_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m,\n\u001b[1;32m     37\u001b[0m                                 arg_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     38\u001b[0m                                 preproc_fn \u001b[38;5;241m=\u001b[39m normalize,\n\u001b[1;32m     39\u001b[0m                                 apply_before_preproc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m                             )\n\u001b[1;32m     42\u001b[0m alt_im, min_eps, inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m path_adversarial_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./AdversarialRobustness/data_adv_vim\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/AdversarialRobustness/loadVim.py:30\u001b[0m, in \u001b[0;36mVimWrapper.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Use the original model to compute the output\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvim_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Return output in a form that includes a `.logits` attribute\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SimpleNamespace(logits\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/AdversarialRobustness/vim/models_mamba.py:541\u001b[0m, in \u001b[0;36mVisionMamba.forward\u001b[0;34m(self, x, return_features, inference_params, if_random_cls_token_position, if_random_token_rank)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, return_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inference_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, if_random_cls_token_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, if_random_token_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 541\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_random_cls_token_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_random_cls_token_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_random_token_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_random_token_rank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_features:\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/AdversarialRobustness/vim/models_mamba.py:478\u001b[0m, in \u001b[0;36mVisionMamba.forward_features\u001b[0;34m(self, x, inference_params, if_random_cls_token_position, if_random_token_rank)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m                 residual \u001b[38;5;241m=\u001b[39m residual\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 478\u001b[0m         hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# get two layers in a single for-loop\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/AdversarialRobustness/vim/models_mamba.py:125\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, hidden_states, residual, inference_params)\u001b[0m\n\u001b[1;32m    115\u001b[0m         hidden_states, residual \u001b[38;5;241m=\u001b[39m fused_add_norm_fn(\n\u001b[1;32m    116\u001b[0m             hidden_states,\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m             eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m         hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mfused_add_norm_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresidual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprenorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m    134\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixer(hidden_states, inference_params\u001b[38;5;241m=\u001b[39minference_params)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states, residual\n",
      "File \u001b[0;32m~/AdversarialRobustness/mamba_ssm/ops/triton/layernorm.py:478\u001b[0m, in \u001b[0;36mrms_norm_fn\u001b[0;34m(x, weight, bias, residual, prenorm, residual_in_fp32, eps)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrms_norm_fn\u001b[39m(x, weight, bias, residual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, prenorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, residual_in_fp32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m):\n\u001b[0;32m--> 478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLayerNormFn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprenorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/AdversarialRobustness/mamba_ssm/ops/triton/layernorm.py:411\u001b[0m, in \u001b[0;36mLayerNormFn.forward\u001b[0;34m(ctx, x, weight, bias, residual, eps, prenorm, residual_in_fp32, is_rms_norm)\u001b[0m\n\u001b[1;32m    405\u001b[0m     bias \u001b[38;5;241m=\u001b[39m bias\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    406\u001b[0m residual_dtype \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    407\u001b[0m     residual\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;28;01mif\u001b[39;00m residual_in_fp32 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    410\u001b[0m )\n\u001b[0;32m--> 411\u001b[0m y, mean, rstd, residual_out \u001b[38;5;241m=\u001b[39m \u001b[43m_layer_norm_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidual_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_rms_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_rms_norm\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(residual_out, weight, bias, mean, rstd)\n\u001b[1;32m    415\u001b[0m ctx\u001b[38;5;241m.\u001b[39mx_shape_og \u001b[38;5;241m=\u001b[39m x_shape_og\n",
      "File \u001b[0;32m~/AdversarialRobustness/mamba_ssm/ops/triton/layernorm.py:129\u001b[0m, in \u001b[0;36m_layer_norm_fwd\u001b[0;34m(x, weight, bias, eps, residual, out_dtype, residual_dtype, is_rms_norm)\u001b[0m\n\u001b[1;32m    127\u001b[0m     residual_dtype \u001b[38;5;241m=\u001b[39m residual\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    128\u001b[0m M, N \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m residual\u001b[38;5;241m.\u001b[39mstride(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load Model and prepare processor\n",
    "model, processor = loadVim.loadVim()\n",
    "normalize = transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "\n",
    "# Predict function\n",
    "def pred(inputs, model, preprocess=True):\n",
    "    # preprocess the image\n",
    "    if preprocess:\n",
    "        inputs = normalize(inputs)\n",
    "\n",
    "    # If input is not batched, batch it\n",
    "    if len(inputs.shape) < 4:\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "\n",
    "    outputs = model(inputs.to(device))\n",
    "    logits = outputs.logits\n",
    "    val, idx = torch.max(logits, dim=1)\n",
    "    return idx\n",
    "\n",
    "# Load dataset\n",
    "def process_image(image):\n",
    "    return processor(image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "\n",
    "data = datasets.ImageFolder('./AdversarialRobustness/imagenette/val', transform=transforms.Lambda(process_image))\n",
    "\n",
    "dataLoader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Adversarial attack\n",
    "# Min Param Perturbation works only with batch size 1 for our purposes\n",
    "min_pert = MinParamPerturbation(\n",
    "                                forward_func = lambda *args, **kwargs: model(*args, **kwargs).logits,\n",
    "                                attack = fgsmAttack,\n",
    "                                arg_name = 'epsilon',\n",
    "                                mode = \"binary\",\n",
    "                                arg_min = 0.001,\n",
    "                                arg_max = 1.5,\n",
    "                                arg_step = 0.001,\n",
    "                                preproc_fn = normalize,\n",
    "                                apply_before_preproc=True\n",
    "                            )\n",
    "\n",
    "alt_im, min_eps, inputs = None, None, None\n",
    "\n",
    "path_adversarial_dataset = './AdversarialRobustness/data_adv_vim'\n",
    "os.makedirs(path_adversarial_dataset, exist_ok=True)\n",
    "\n",
    "log = []\n",
    "\n",
    "for i, (input, label) in enumerate(dataLoader):\n",
    "    input = input.to(device)\n",
    "    # Convert label item to ImageNet label\n",
    "    label = torch.tensor([netteToImageNetConv[label.item()]]).to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    prediction = pred(input, model)\n",
    "\n",
    "    if prediction == label:\n",
    "        # We only care for adversarial examples in the case when the model could correctly predict otherwise\n",
    "        attack_kwargs={'model':model,'true_label':label}\n",
    "\n",
    "        alt_im, min_eps = min_pert.evaluate(input, attack_kwargs=attack_kwargs, target=label)\n",
    "\n",
    "        altpred = pred(alt_im, model)\n",
    "        print(f\"adv_{i} is a {model.config.id2label[label.item()]} but classifies as {model.config.id2label[altpred.item()]} with epsilon {min_eps}\")\n",
    "\n",
    "        mse, ssim_val, linf = calcImageDistanceMetrics(input, alt_im)\n",
    "        log.append({\"index\": i, \"label\": label.item(), \"prediction\": altpred.item(), \"epsilon\": min_eps, \"mse\": mse, \"ssim\": ssim_val, \"linf\": linf})\n",
    "\n",
    "        # Save the adversarial example to new dataset\n",
    "        saveImageTensor(alt_im, path_adversarial_dataset, label, f\"adv_{i}\")\n",
    "    else:\n",
    "        print(f\"Incorrect classification, label: {label}, prediction: {prediction}, skipping...\")\n",
    "\n",
    "# Pickle the log\n",
    "with open(f\"{path_adversarial_dataset}/log.pkl\", \"wb\") as f:\n",
    "    pickle.dump(log, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c074bd-214e-447d-a063-59896339288d",
   "metadata": {},
   "source": [
    "# Generate Celeb Adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fc9a5-6b62-4a7d-919f-a4e397c9f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and prepare processor\n",
    "\n",
    "model, processor = loadVim.prepareDownstreamModel()\n",
    "normalize = transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "\n",
    "# Predict function\n",
    "def pred(inputs, model, preprocess=True):\n",
    "    # preprocess the image\n",
    "    if preprocess:\n",
    "        inputs = normalize(inputs)\n",
    "\n",
    "    # If input is not batched, batch it\n",
    "    if len(inputs.shape) < 4:\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "\n",
    "    outputs = model(inputs.to(device))\n",
    "    logits = outputs.logits\n",
    "    val, idx = torch.max(logits, dim=1)\n",
    "    return idx\n",
    "\n",
    "# Load dataset\n",
    "def process_image(image):\n",
    "    return processor(image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "\n",
    "data = datasets.ImageFolder('./AdversarialRobustness/imagenette/val', transform=transforms.Lambda(process_image))\n",
    "\n",
    "dataLoader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Adversarial attack\n",
    "# Min Param Perturbation works only with batch size 1 for our purposes\n",
    "min_pert = MinParamPerturbation(\n",
    "                                forward_func = lambda *args, **kwargs: model(*args, **kwargs).logits,\n",
    "                                attack = fgsmAttack,\n",
    "                                arg_name = 'epsilon',\n",
    "                                mode = \"binary\",\n",
    "                                arg_min = 0.001,\n",
    "                                arg_max = 1.5,\n",
    "                                arg_step = 0.001,\n",
    "                                preproc_fn = normalize,\n",
    "                                apply_before_preproc=True\n",
    "                            )\n",
    "\n",
    "alt_im, min_eps, inputs = None, None, None\n",
    "\n",
    "path_adversarial_dataset = './AdversarialRobustness/data_adv_vim'\n",
    "os.makedirs(path_adversarial_dataset, exist_ok=True)\n",
    "\n",
    "log = []\n",
    "\n",
    "for i, (input, label) in enumerate(dataLoader):\n",
    "    input = input.to(device)\n",
    "    # Convert label item to ImageNet label\n",
    "    label = torch.tensor([netteToImageNetConv[label.item()]]).to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    prediction = pred(input, model)\n",
    "\n",
    "    if prediction == label:\n",
    "        # We only care for adversarial examples in the case when the model could correctly predict otherwise\n",
    "        attack_kwargs={'model':model,'true_label':label}\n",
    "\n",
    "        alt_im, min_eps = min_pert.evaluate(input, attack_kwargs=attack_kwargs, target=label)\n",
    "\n",
    "        altpred = pred(alt_im, model)\n",
    "        print(f\"adv_{i} is a {model.config.id2label[label.item()]} but classifies as {model.config.id2label[altpred.item()]} with epsilon {min_eps}\")\n",
    "\n",
    "        mse, ssim_val, linf = calcImageDistanceMetrics(input, alt_im)\n",
    "        log.append({\"index\": i, \"label\": label.item(), \"prediction\": altpred.item(), \"epsilon\": min_eps, \"mse\": mse, \"ssim\": ssim_val, \"linf\": linf})\n",
    "\n",
    "        # Save the adversarial example to new dataset\n",
    "        saveImageTensor(alt_im, path_adversarial_dataset, label, f\"adv_{i}\")\n",
    "    else:\n",
    "        print(f\"Incorrect classification, label: {label}, prediction: {prediction}, skipping...\")\n",
    "\n",
    "# Pickle the log\n",
    "with open(f\"{path_adversarial_dataset}/log.pkl\", \"wb\") as f:\n",
    "    pickle.dump(log, f)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
